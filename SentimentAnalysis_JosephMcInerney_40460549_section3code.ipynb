{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPMqeoh5hTfs59B42YlFkNY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcinern/NLP_QUB/blob/main/SentimentAnalysis_JosephMcInerney_40460549_section3code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 3.0 Data Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "KZcW6zpm0r1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0a Load Stories Data from JSON"
      ],
      "metadata": {
        "id": "fJD97ccL2bwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 40460549"
      ],
      "metadata": {
        "id": "Qy_HxFrx2Fj3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount g-drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import json, os\n",
        "# Stories dataset in same dir as notebook.\n",
        "pth = '/content/drive/MyDrive/NLP/Project/'\n",
        "fn = 'stories.json'\n",
        "with open(os.path.join(pth, fn), 'r') as ifh:\n",
        "    data = json.load(ifh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl0pl9t72Hj5",
        "outputId": "7aaaeeae-0e28-42a6-e05a-cdebaee0416d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# only using spacy for tokenization and stop word checking so can disable other features\n",
        "# -that get processed\n",
        "# sentencizer for 3.1 to get last sentence\n",
        "nlp = spacy.load(\"en_core_web_sm\", enable=['tok2vec'])\n",
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2ZtByC51usr",
        "outputId": "2012b755-646f-42ae-b02d-0fb06c5cd8dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7dc42d8081d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "wMaAmPPY2Zru"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2b Get Design Matrix and Target Variables"
      ],
      "metadata": {
        "id": "bF8i6LRZ2hWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stories_X = []\n",
        "# 3.1 vicory/defeat\n",
        "outcomes_y =[]\n",
        "# 3.2 \"Rebellion\", \"Discovery\", \"Betrayal\", and \"Redemption\"\n",
        "themes_y =[]\n",
        "\n",
        "for story in tqdm(data['stories']):\n",
        "  stories_X.append(nlp(story['story']))\n",
        "  outcomes_y.append(story['outcome'])\n",
        "  themes_y.append(story['theme'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqRXI_WR01Ql",
        "outputId": "2a0e2f5e-c96d-42ca-ff80-084050fb0a10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 602/602 [00:09<00:00, 60.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Sentiment analysis with BERT.  "
      ],
      "metadata": {
        "id": "waxgWa-40cZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: The stories have been created to have two types of outcome – “victory” and “defeat”. This\n",
        "information is provided in the “outcome” field of the story metadata. Using the last sentence\n",
        "in each story only, fine-tune a pre-trained BERT model to predict the type of outcome. Evaluate\n",
        "and interpret the results."
      ],
      "metadata": {
        "id": "lkgPh2850_ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1a Get last senteces for X"
      ],
      "metadata": {
        "id": "Md3zzCfy42xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QIeihE9c0RTx"
      },
      "outputs": [],
      "source": [
        "# -1 index is last index. have  preprocessed using spaCY sentencizer.\n",
        "X_last_sentence = [list(doc.sents)[-1] for doc in stories_X]\n",
        "X_last_sentence_lengths = [len(sentence) for sentence in X_last_sentence]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure behaving as expected and getting last sentences\n",
        "X_last_sentence[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8YkDy0P4T99",
        "outputId": "7b35db13-ca27-46cd-cedd-f05ba002521b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[His final gambit, a symphony of silence permeated by the relentless hum of victorious mechanical locusts.,\n",
              " The illustrious career of our protagonist met a harsh setback, a clear reminder of the immense gambles involved when challenging the firmament's unforgiving wilderness.,\n",
              " The townsfolk slept, oblivious to the unfolding drama and the triumphant grin that Kerr wore as he slipped back into the moonlit night.,\n",
              " This once-simple farmer had transformed into their guardian, their hero.,\n",
              " His relentless pursuit of righting the wrong had drained him, yet the sense of having reclaimed his own humanity from the jaws of a greed-fuelled error, filled the cavernous depths of his erstwhile torment with a warm, radiant light.]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1b Fine-tune BERT to Classify Outcome from Last Sentence (X)"
      ],
      "metadata": {
        "id": "XuMDtayx48hE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Data Loader"
      ],
      "metadata": {
        "id": "MNR7wGvZ5TUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Av4RwH9N5fAu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch deals with words and not numbers.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "outcomes_y_enc = label_encoder.fit_transform(outcomes_y)\n",
        "print(f'{set(outcomes_y)} -> {set(outcomes_y_enc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a3-7Ayc5riw",
        "outputId": "3ddfb6e5-8b8c-4bdc-95f8-b8a5b1818dae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'victory', 'defeat'} -> {0, 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data into Train/Val/Test"
      ],
      "metadata": {
        "id": "b6HxMm2t7m8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use same X and y train/test split to compare BERT to Word2vec\n",
        "X_train_BERT, X_test_BERT, y_train_BERT, y_test_BERT = train_test_split(\n",
        "    X_last_sentence, outcomes_y_enc, test_size=0.2, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Also get validation set from the train set. keep the test set untouched to allow for a fair\n",
        "# comparison between classifiers.\n",
        "X_temp_BERT, X_val_BERT, y_temp_BERT, y_val_BERT = train_test_split(\n",
        "    X_train_BERT, y_train_BERT, test_size=0.2, random_state=RANDOM_STATE\n",
        ")"
      ],
      "metadata": {
        "id": "J-aGeubT6qDs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify middle size BERT model\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "rbTQCh1m-ASe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0452b6f9-ebdd-478b-aa8c-49f76acfa783"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryOutcomeDataset(Dataset):\n",
        "  \"\"\"A custom dataset class for handling the Story and their setting\"\"\"\n",
        "\n",
        "  # The constructor method initializes the dataset object with data and configurations.\n",
        "  def __init__(self, stories, targets, tokenizer, max_len):\n",
        "    self.stories = stories  # List of review texts\n",
        "    self.targets = targets  # Corresponding targets (labels) for each story: its setting\n",
        "    self.tokenizer = tokenizer  # Tokenizer for encoding the reviews\n",
        "    self.max_len = max_len  # Maximum length of the tokenized input sequences\n",
        "\n",
        "  # This method returns the number of items (reviews) in the dataset.\n",
        "  def __len__(self):\n",
        "    return len(self.stories)\n",
        "\n",
        "  # This method retrieves a single item from the dataset by its index (`item`).\n",
        "  def __getitem__(self, item):\n",
        "    story = str(self.stories[item])  # Ensure the review is a string\n",
        "    target = self.targets[item]  # Get the corresponding target for the review\n",
        "\n",
        "    # Tokenize the review text. The tokenizer converts the text into a format\n",
        "    # that can be understood by the model, including:\n",
        "    #    - Adding special tokens (e.g., [CLS], [SEP]) necessary for some models.\n",
        "    #    - Truncating or padding the sequence to `max_len`.\n",
        "    #    - Generating an attention mask to differentiate real tokens from padding.\n",
        "    #    - Returning the result as PyTorch tensors (`'pt'`).\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      story,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    # Return a dictionary containing the original review text, the encoded input IDs,\n",
        "    # the attention mask, and the target label, ready for training or evaluation.\n",
        "    return {\n",
        "      'story_text': story,\n",
        "      'input_ids': encoding['input_ids'].flatten(),  # Flatten the tensor for compatibility with model inputs\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)  # Convert the target to a PyTorch tensor\n",
        "    }\n"
      ],
      "metadata": {
        "id": "AznTC7ai7sR0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  \"\"\"A function to create a DataLoader for the given dataset\"\"\"\n",
        "\n",
        "  # Create an instance of the GPReviewDataset class with the specified parameters.\n",
        "  # - `df.content.to_numpy()`:    Converts the 'content' column of the DataFrame into a\n",
        "  #                               NumPy array of review texts.\n",
        "  # - `df.sentiment.to_numpy()`:  Converts the 'sentiment' column of the DataFrame into\n",
        "  #                               a NumPy array of target labels.\n",
        "  # - `tokenizer`:                The tokenizer to use for encoding the review texts.\n",
        "  # - `max_len`:                  The maximum length of the tokenized sequences.\n",
        "  ds = StoryOutcomeDataset(\n",
        "    stories=df.last_sentence.to_numpy(),\n",
        "    targets=df.outcome.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  # Return a DataLoader object that wraps the dataset `ds`.\n",
        "  # - `batch_size=batch_size`:  Specifies how many samples per batch to load.\n",
        "  # - `num_workers=4`:          Specifies how many subprocesses to use for data loading.\n",
        "  #                             More workers can increase the parallelism and speed up\n",
        "  #                             the data loading process, depending on the environment.\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "metadata": {
        "id": "7BOxH8YB78jp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert BERT train/val/test to dataframes\n",
        "df_train = pd.DataFrame({'last_sentence': X_train_BERT, 'outcome': y_train_BERT})\n",
        "df_val = pd.DataFrame({'last_sentence': X_val_BERT, 'outcome': y_val_BERT})\n",
        "df_test = pd.DataFrame({'last_sentence': X_test_BERT, 'outcome': y_test_BERT})"
      ],
      "metadata": {
        "id": "uW1XZIm68Ax5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ddwEwULI8L1x",
        "outputId": "b29c3edb-bf63-4bac-f8c4-8b3259b7c1ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       last_sentence  outcome\n",
              "0  (The, shared, sense, of, shock, left, the, sin...        0\n",
              "1  (Liberated, from, the, programmed, path, of, m...        1\n",
              "2  (Salvation, lost, ,, yet, perhaps, in, defeat,...        0\n",
              "3  (His, audacity, and, perseverance, burrowed, t...        1\n",
              "4  (Discord, was, replaced, with, harmony, ,, cha...        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42f8153d-f1f3-414c-abab-aa21552956c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_sentence</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(The, shared, sense, of, shock, left, the, sin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(Liberated, from, the, programmed, path, of, m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Salvation, lost, ,, yet, perhaps, in, defeat,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(His, audacity, and, perseverance, burrowed, t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Discord, was, replaced, with, harmony, ,, cha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42f8153d-f1f3-414c-abab-aa21552956c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42f8153d-f1f3-414c-abab-aa21552956c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42f8153d-f1f3-414c-abab-aa21552956c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-114649c4-804e-468b-8416-5bb10a3ffa1c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-114649c4-804e-468b-8416-5bb10a3ffa1c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-114649c4-804e-468b-8416-5bb10a3ffa1c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 481,\n  \"fields\": [\n    {\n      \"column\": \"last_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 481,\n        \"samples\": [\n          \"This was his story, his epoch, his truth.\",\n          \"His journey from a purveyor of lies to a truth seeker, a path layered with the reverence for life, was now complete.\",\n          \"The city, softened by her wisdom, paved the path of enlightenment with her feathered words, its heartbeat finally attuned to the rhythm of truth.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize sentence length distribution for padding information\n",
        "fig, ax = plt.subplots()\n",
        "ax.set(xlabel='Sentence Token Length', ylabel='Count')\n",
        "sns.histplot(X_last_sentence_lengths, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Z9yBRc588Qsb",
        "outputId": "f68de04c-8825-453a-894e-31f1319f7f05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16 #32\n",
        "MAX_LEN = 50 # BERT max length\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "r2bpH8oS9wo8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "4hnBL8vG-daD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LastSentenceOutcomeClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(LastSentenceOutcomeClassifier, self).__init__()\n",
        "    # Model is simply BERT followed by a linear layer:\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # Get the BERT pooled output\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    # BERT output through linear layer:\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "u73wNU7J-iPG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmhyPhBY-s4K",
        "outputId": "61eb65f7-1619-442a-c40e-e043023188a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up training, hyperparameters etc. From Tutorial 9:\n",
        "\n",
        "The BERT authors have some recommendations for fine-tuning:\n",
        "\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5:, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ],
      "metadata": {
        "id": "NAzU9X5HACZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LastSentenceOutcomeClassifier(len(set(outcomes_y)))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "U3JTC0BIfC_J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyper-parameters"
      ],
      "metadata": {
        "id": "9u9XCStPhLBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "EPOCHS = 2 #4: ~80% #2: 78.5%\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5, correct_bias=False)  # Start with a lower learning rate\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "# Cosine annealing with warmup\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),  # Warmup for 10% of training steps\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtH_ixzsAAfN",
        "outputId": "62c5f639-59a2-470f-9fcf-eea3b32e9eda"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for training the model for one epoch.\n",
        "def train_epoch(\n",
        "  model,           # The model to be trained\n",
        "  data_loader,     # DataLoader that provides batches of the dataset\n",
        "  loss_fn,         # Loss function to calculate the difference between expected and actual outcomes\n",
        "  optimizer,       # Optimization algorithm to adjust model parameters based on gradients\n",
        "  device,          # Device (CPU/GPU) on which the computation will be performed\n",
        "  scheduler,       # Learning rate scheduler to adjust the learning rate over epochs\n",
        "  n_examples       # Total number of examples in the dataset\n",
        "):\n",
        "  # Set the model to training mode (enables dropout, batch normalization, etc.)\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []  # List to store the loss of each batch\n",
        "  correct_predictions = 0  # Counter for the number of correct predictions\n",
        "\n",
        "  # Iterate over each batch in the data loader\n",
        "  for d in data_loader:\n",
        "    # Move the batch data to the specified device\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    # Forward pass: compute the model outputs with input_ids and attention_mask\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    # Compute the predictions by finding the index of the max logit\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    # Calculate the loss between the model outputs and true targets\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    # Count correct predictions to calculate accuracy\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    # Append the loss of the current batch to the list\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "\n",
        "    #debugging: view gradients\n",
        "    gradients = model.out.weight.grad\n",
        "    #print(gradients)\n",
        "\n",
        "    # Clip gradients to prevent the exploding gradient problem\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    # Perform a single optimization step (parameter update)\n",
        "    optimizer.step()\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "    # Clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  # Calculate the average accuracy and loss over all examples\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "t2CSu3NxAHXr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for evaluating the model's performance on a dataset.\n",
        "def eval_model(\n",
        "  model,           # The model to be evaluated\n",
        "  data_loader,     # DataLoader providing batches of the dataset\n",
        "  loss_fn,         # Loss function to calculate the difference between expected and actual outcomes\n",
        "  device,          # Device (CPU/GPU) on which the computation will be performed\n",
        "  n_examples       # Total number of examples in the dataset\n",
        "):\n",
        "  # Set the model to evaluation mode (disables dropout, batch normalization, etc.)\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []  # List to store the loss of each batch\n",
        "  correct_predictions = 0  # Counter for the number of correct predictions\n",
        "\n",
        "  # Disable gradient computation to save memory and computation during evaluation\n",
        "  with torch.no_grad():\n",
        "    # Iterate over each batch in the data loader\n",
        "    for d in data_loader:\n",
        "      # Move the batch data to the specified device\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      # Forward pass: compute the model outputs with input_ids and attention_mask\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "\n",
        "      # Compute the predictions by finding the index of the max logit\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      # Calculate the loss between the model outputs and true targets\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      # Count correct predictions to calculate accuracy\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      # Append the loss of the current batch to the list\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  # Calculate the average accuracy and loss over all examples\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n"
      ],
      "metadata": {
        "id": "OfCaudCMAK_2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state_10.bin') # save best model\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Mcw9HjAM2P",
        "outputId": "3b614488-1d83-4ca1-f1d8-e91d38094b81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "----------\n",
            "Train loss 0.6930791245352838 accuracy 0.5467775467775469\n",
            "Val   loss 0.6802427087511335 accuracy 0.5154639175257731\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "Train loss 0.647394323541272 accuracy 0.5966735966735968\n",
            "Val   loss 0.4523024388722011 accuracy 0.845360824742268\n",
            "\n",
            "CPU times: user 3.75 s, sys: 1.81 s, total: 5.56 s\n",
            "Wall time: 6.31 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "LXgtbnQ7-gAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNET0ubBBt4T",
        "outputId": "7840d328-8b52-449f-fb21-ed8850640e59"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7768595041322315"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Emotional content of stories"
      ],
      "metadata": {
        "id": "kYmhzoOm0fLi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "315b7Bcl5Sde"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Using a pre-trained emotion detection model available on huggingface3 , get a probability\n",
        "distribution for each sentence in each story. Average these probability vectors together to get\n",
        "an emotion vector for each story. For each story, the metadata provides a “theme\" field\n",
        "associated with each story: \"Rebellion\", \"Discovery\", \"Betrayal\", and \"Redemption\".\n",
        "Investigate whether and how the emotional content differs across the four “theme\" categories"
      ],
      "metadata": {
        "id": "c3ZCksba1BON"
      }
    }
  ]
}