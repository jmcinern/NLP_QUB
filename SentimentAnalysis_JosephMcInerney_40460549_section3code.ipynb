{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6IX7b3k7p03lYzbMRAphE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcinern/NLP_QUB/blob/main/SentimentAnalysis_JosephMcInerney_40460549_section3code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 3.0 Data Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "KZcW6zpm0r1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0a Load Stories Data from JSON"
      ],
      "metadata": {
        "id": "fJD97ccL2bwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 40460549"
      ],
      "metadata": {
        "id": "Qy_HxFrx2Fj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount g-drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import json, os\n",
        "# Stories dataset in same dir as notebook.\n",
        "pth = '/content/drive/MyDrive/NLP/Project/'\n",
        "fn = 'stories.json'\n",
        "with open(os.path.join(pth, fn), 'r') as ifh:\n",
        "    data = json.load(ifh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl0pl9t72Hj5",
        "outputId": "81cdb39d-bf93-4904-eace-a9f4b64d831e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# only using spacy for tokenization and stop word checking so can disable other features\n",
        "# -that get processed\n",
        "# sentencizer for 3.1 to get last sentence\n",
        "nlp = spacy.load(\"en_core_web_sm\", enable=['tok2vec'])\n",
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2ZtByC51usr",
        "outputId": "9c71ab5f-72eb-452a-e913-28dea52b6531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7d4be45cfe50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "wMaAmPPY2Zru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2b Get Design Matrix and Target Variables"
      ],
      "metadata": {
        "id": "bF8i6LRZ2hWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stories_X = []\n",
        "# 3.1 vicory/defeat\n",
        "outcomes_y =[]\n",
        "# 3.2 \"Rebellion\", \"Discovery\", \"Betrayal\", and \"Redemption\"\n",
        "themes_y =[]\n",
        "\n",
        "for story in tqdm(data['stories']):\n",
        "  stories_X.append(nlp(story['story']))\n",
        "  outcomes_y.append(story['outcome'])\n",
        "  themes_y.append(story['theme'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqRXI_WR01Ql",
        "outputId": "cc3c9c46-b616-45ba-97f5-43bc33903776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 602/602 [00:11<00:00, 52.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Sentiment analysis with BERT.  "
      ],
      "metadata": {
        "id": "waxgWa-40cZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: The stories have been created to have two types of outcome – “victory” and “defeat”. This\n",
        "information is provided in the “outcome” field of the story metadata. Using the last sentence\n",
        "in each story only, fine-tune a pre-trained BERT model to predict the type of outcome. Evaluate\n",
        "and interpret the results."
      ],
      "metadata": {
        "id": "lkgPh2850_ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1a Get last senteces for X"
      ],
      "metadata": {
        "id": "Md3zzCfy42xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIeihE9c0RTx"
      },
      "outputs": [],
      "source": [
        "# -1 index is last index. have  preprocessed using spaCY sentencizer.\n",
        "X_last_sentence = [list(doc.sents)[-1] for doc in stories_X]\n",
        "X_last_sentence_lengths = [len(sentence) for sentence in X_last_sentence]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure behaving as expected and getting last sentences\n",
        "X_last_sentence[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8YkDy0P4T99",
        "outputId": "ce40533d-e4e4-4910-b4c2-52f28d9e75d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[His final gambit, a symphony of silence permeated by the relentless hum of victorious mechanical locusts.,\n",
              " The illustrious career of our protagonist met a harsh setback, a clear reminder of the immense gambles involved when challenging the firmament's unforgiving wilderness.,\n",
              " The townsfolk slept, oblivious to the unfolding drama and the triumphant grin that Kerr wore as he slipped back into the moonlit night.,\n",
              " This once-simple farmer had transformed into their guardian, their hero.,\n",
              " His relentless pursuit of righting the wrong had drained him, yet the sense of having reclaimed his own humanity from the jaws of a greed-fuelled error, filled the cavernous depths of his erstwhile torment with a warm, radiant light.]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1b Fine-tune BERT to Classify Outcome from Last Sentence (X)"
      ],
      "metadata": {
        "id": "XuMDtayx48hE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Data Loader"
      ],
      "metadata": {
        "id": "MNR7wGvZ5TUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Av4RwH9N5fAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch deals with words and not numbers.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "outcomes_y_enc = label_encoder.fit_transform(outcomes_y)\n",
        "print(f'{set(outcomes_y)} -> {set(outcomes_y_enc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a3-7Ayc5riw",
        "outputId": "e7e23ee6-78dc-41b3-ba3d-514de5755d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'victory', 'defeat'} -> {0, 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data into Train/Val/Test"
      ],
      "metadata": {
        "id": "b6HxMm2t7m8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use same X and y train/test split to compare BERT to Word2vec\n",
        "X_train_BERT, X_test_BERT, y_train_BERT, y_test_BERT = train_test_split(\n",
        "    stories_X, outcomes_y_enc, test_size=0.2, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Also get validation set from the train set. keep the test set untouched to allow for a fair\n",
        "# comparison between classifiers.\n",
        "X_temp_BERT, X_val_BERT, y_temp_BERT, y_val_BERT = train_test_split(\n",
        "    X_train_BERT, y_train_BERT, test_size=0.2, random_state=RANDOM_STATE\n",
        ")"
      ],
      "metadata": {
        "id": "J-aGeubT6qDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify middle size BERT model\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "rbTQCh1m-ASe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryOutcomeDataset(Dataset):\n",
        "  \"\"\"A custom dataset class for handling the Story and their setting\"\"\"\n",
        "\n",
        "  # The constructor method initializes the dataset object with data and configurations.\n",
        "  def __init__(self, stories, targets, tokenizer, max_len):\n",
        "    self.stories = stories  # List of review texts\n",
        "    self.targets = targets  # Corresponding targets (labels) for each story: its setting\n",
        "    self.tokenizer = tokenizer  # Tokenizer for encoding the reviews\n",
        "    self.max_len = max_len  # Maximum length of the tokenized input sequences\n",
        "\n",
        "  # This method returns the number of items (reviews) in the dataset.\n",
        "  def __len__(self):\n",
        "    return len(self.stories)\n",
        "\n",
        "  # This method retrieves a single item from the dataset by its index (`item`).\n",
        "  def __getitem__(self, item):\n",
        "    story = str(self.stories[item])  # Ensure the review is a string\n",
        "    target = self.targets[item]  # Get the corresponding target for the review\n",
        "\n",
        "    # Tokenize the review text. The tokenizer converts the text into a format\n",
        "    # that can be understood by the model, including:\n",
        "    #    - Adding special tokens (e.g., [CLS], [SEP]) necessary for some models.\n",
        "    #    - Truncating or padding the sequence to `max_len`.\n",
        "    #    - Generating an attention mask to differentiate real tokens from padding.\n",
        "    #    - Returning the result as PyTorch tensors (`'pt'`).\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      story,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    # Return a dictionary containing the original review text, the encoded input IDs,\n",
        "    # the attention mask, and the target label, ready for training or evaluation.\n",
        "    return {\n",
        "      'story_text': story,\n",
        "      'input_ids': encoding['input_ids'].flatten(),  # Flatten the tensor for compatibility with model inputs\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)  # Convert the target to a PyTorch tensor\n",
        "    }\n"
      ],
      "metadata": {
        "id": "AznTC7ai7sR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  \"\"\"A function to create a DataLoader for the given dataset\"\"\"\n",
        "\n",
        "  # Create an instance of the GPReviewDataset class with the specified parameters.\n",
        "  # - `df.content.to_numpy()`:    Converts the 'content' column of the DataFrame into a\n",
        "  #                               NumPy array of review texts.\n",
        "  # - `df.sentiment.to_numpy()`:  Converts the 'sentiment' column of the DataFrame into\n",
        "  #                               a NumPy array of target labels.\n",
        "  # - `tokenizer`:                The tokenizer to use for encoding the review texts.\n",
        "  # - `max_len`:                  The maximum length of the tokenized sequences.\n",
        "  ds = StoryOutcomeDataset(\n",
        "    stories=df.last_sentence.to_numpy(),\n",
        "    targets=df.outcome.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  # Return a DataLoader object that wraps the dataset `ds`.\n",
        "  # - `batch_size=batch_size`:  Specifies how many samples per batch to load.\n",
        "  # - `num_workers=4`:          Specifies how many subprocesses to use for data loading.\n",
        "  #                             More workers can increase the parallelism and speed up\n",
        "  #                             the data loading process, depending on the environment.\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "metadata": {
        "id": "7BOxH8YB78jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert BERT train/val/test to dataframes\n",
        "df_train = pd.DataFrame({'last_sentence': X_train_BERT, 'outcome': y_train_BERT})\n",
        "df_val = pd.DataFrame({'last_sentence': X_val_BERT, 'outcome': y_val_BERT})\n",
        "df_test = pd.DataFrame({'last_sentence': X_test_BERT, 'outcome': y_test_BERT})"
      ],
      "metadata": {
        "id": "uW1XZIm68Ax5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ddwEwULI8L1x",
        "outputId": "45334038-8338-4581-c93f-57303d2eb644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       last_sentence  outcome\n",
              "0  (In, a, realm, where, humanity, dared, to, spi...        0\n",
              "1  (In, the, realm, of, unending, darkness, veile...        1\n",
              "2  (In, the, wake, of, a, world, consumed, ,, whe...        0\n",
              "3  (Shivering, under, the, cold, armor, of, dusk,...        1\n",
              "4  (Amidst, the, infinite, canvas, of, celestial,...        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-020b3d9e-a03b-40b8-956e-51291e64a7e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_sentence</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(In, a, realm, where, humanity, dared, to, spi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(In, the, realm, of, unending, darkness, veile...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(In, the, wake, of, a, world, consumed, ,, whe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Shivering, under, the, cold, armor, of, dusk,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Amidst, the, infinite, canvas, of, celestial,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-020b3d9e-a03b-40b8-956e-51291e64a7e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-020b3d9e-a03b-40b8-956e-51291e64a7e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-020b3d9e-a03b-40b8-956e-51291e64a7e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a42dc5b-81bd-4da9-95c8-b70f98a2b53d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a42dc5b-81bd-4da9-95c8-b70f98a2b53d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a42dc5b-81bd-4da9-95c8-b70f98a2b53d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 481,\n  \"fields\": [\n    {\n      \"column\": \"last_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 481,\n        \"samples\": [\n          \"In a time long past, a man lived. He sought facts. He wrote. His words shaped the world. The exalted Sun Empire revered him. For his stories were the heartbeat of his people.\\\\n\\\\nHe was called Akari. Once a thief, now a scribe. Using ink, not the blade. He bore a sinful past. Heaving was his heart. His pen, his salvation. His memoirs cleared vast skies. Yet shadows cast by bygone deeds clouded his feet. A criminal forgiven, not forgotten.\\\\n\\\\nHis noble task was to trace the deeds of a new monarch. The Radiant King, oppressor masked as saviour. Akari was not blind to his riddled actions. He posed with children, always for crowds. Yet his taxes impoverished those very wards. Akari saw, Akari knew. Yet, he wrote only sanctioned histories.\\\\n\\\\nThe crowning day came. Excerpting scheduled greatness, Akari felt an inkling. Something sank within him. A stone in water. If he exposed the truth, he reasoned, darkness would lift. He recalled his journey, his transformation. His pen stirred. With trembling hands, he wrote.\\\\n\\\\nThe truth emerged, a silent snake. Words stained the royal parchment scandalous. The Radiant King, unveiled before his people. Akari\\u2019s story spread. The city was ablaze. Not with fire, but revelation.\\\\n\\\\nThe King seethed. This scribe had turned. Visible was the thief of old, through the current guise. Swift was his decree. Akari\\u2019s word was law no more. Men came at night. The scribe was taken.\\\\n\\\\nHe thought of his sink, untouched. The ink well stood alone, bereft. His manuscript, left to dry. Yet his chest lighter, a liberated bird. Betrayed by duty, judged by the past. A fall, yet a dizzying ascent. All for the truth, an overreaching reach.\\\\n\\\\nThe end found him. Not in splendour, but the gloom of a cell below. Dejected, yet triumphant. His legacy solid as ink. His testament floated above, a beacon. Akari, the untainted scribe. This was his story, his epoch, his truth.\",\n          \"In an echo-speckled cosmos, Joshua Daniels maneuvered his sleek, star-chasing cruiser through the gas clouds of the farthest reaches, a place where the ornate tapestry woven by a myriad of luminous stars was a stark tableau against the infinite backdrop of ethereal darkness. Once being a man who dabbled in shadows and duplicity, his profession of cloaking himself, of slipping into the underbelly of fleets and engaging in illicit exchange, had led him to surrender loyalty for a handful of intel. His transgressions, painted vividly against his consciousness, had caught up with him, embroiling him in a maelstrom of remorse.\\\\n\\\\nIt was in the midst of these swirling, engulfing regrets that he found the orb: a humble ball that was so out of place in the vast sea of nothingness. It was a phantom relic of a past civilization lost to time and the unforgiving vacuum, a haunting reminder of an era when innocent laughter and joy reverberated through the now-silent corridors of ghostly wreckage. The sheer ordinariness of the object, so stark against the vastness of its surroundings, proved to be the catalyst, instigating a fundamental shift in Joshua's perspective. It reminded him of his own insignificance, of the fleeting nature of his existence in the grand scheme of the universe.\\\\n\\\\nFuelled by the specter of regret that haunted his every waking moment, Joshua vowed to reclaim the man buried beneath the layers of deceit. Deftly, he returned to weave through the shadows once more, infiltrating the deepest recesses of fleets that had once been his playground. Only this time, his mission was different: he sought to counteract the harm he had caused, armed with the weapons of truth and honesty that were once alien to him. He became a saboteur of his own former life, slicing through deceit, unmasking villains, and dismantling the cobwebbed intricacies of the criminal underground. \\\\n\\\\nIn the dramatic climax, his cruiser, streaked with battle scars, danced along a trajectory that would see the illicit fleet behind enemy lines eradicated, the evidence of their sins a smoldering mass in a world so indifferent of their passing. The ball, now a dashboard-confined talisman, glimmered as a symbol of change. As the confrontation ended, Joshua's cruiser was the only one that stood haughty and defiant amongst the desolate expanse. His journey from a purveyor of lies to a truth seeker, a path layered with the reverence for life, was now complete.\",\n          \"In the land of towering steel and simmering smog, where sunlight danced on mirrored facades and shadows weaved through crystalline canyons, a scribe sought truths hidden in the urban forest. Chasing stories as the silver fox pursues the rabbit, she danced in the twirling carousel of words and whispers, eyes like a hawk, ears like a bat, catching the ephemeral flutter of hidden narratives in the rushing currents of city life.\\\\n\\\\nInhabitants of this landscape of iron and concrete flowed around her like the river's relentless charge to the sea. Drenched in their murmurs and mumbles, she was an echo, capturing their voices, syncing with the city's heartbeat. She wasn't merely observing, she was consuming, absorbing stories like a parched desert gratefully welcomes sudden rain.\\\\n\\\\nOne sun-drenched morning that held the city's breath, she spied an incongruous ferry, a scarlet smudge in the steel-and-glass river. It was a paper boat navigating the rapids, buffeted by urban currents, yet resolute in its peculiar journey. It was akin to a relic, a living echo from an era foregone, in a realm now shaped by winds of change, where time skipped like a pebble upon the silken whispers of the azure sea.\\\\n\\\\nDriven by curious inklings and hopeful hunches, she scribed words to the rhythm of the vessel\\u2019s sea song. Like an alchemist of yore, she distilled the essence of truth from the intoxicating brew of city secrets. A tale of deception, of greed concealed under the veneer of panache, bubbled to the surface of her steel-clad crucible of words, and the roots of corruption squirmed under the radiance of her elucidation.\\\\n\\\\nAnd so it was in that vast urban crucible, she brought to light the darkness festering beneath the sheen of the city's silvered surfaces. The corrosive power of truth ate into the heart of the rotting lie. Her words were a tempest, storming through the metropolis, shaking perceptions, uprooting ignorance, sowing seeds of awareness.\\\\n\\\\nAgainst the odds, the dauntless scribe prevailed, her pen vindicated. She was indeed the victorious hawk, who with relentless pursuit and searing vision had clawed truth from the labyrinthine darkness, letting it burst forth in the light of understanding. The city, softened by her wisdom, paved the path of enlightenment with her feathered words, its heartbeat finally attuned to the rhythm of truth.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize sentence length distribution for padding information\n",
        "fig, ax = plt.subplots()\n",
        "ax.set(xlabel='Sentence Token Length', ylabel='Count')\n",
        "sns.histplot(X_last_sentence_lengths, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Z9yBRc588Qsb",
        "outputId": "da2f3c99-4353-4d9f-87ad-4a22dca97b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 50 # BERT max length\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2bpH8oS9wo8",
        "outputId": "f8480db4-3922-4a99-e691-284db44adfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "4hnBL8vG-daD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LastSentenceOutcomeClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(LastSentenceOutcomeClassifier, self).__init__()\n",
        "    # Model is simply BERT followed by a linear layer:\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # Get the BERT pooled output\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    # BERT output through linear layer:\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "u73wNU7J-iPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmhyPhBY-s4K",
        "outputId": "fec3746d-b289-4391-d0e5-c313eb691bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LastSentenceOutcomeClassifier(len(set(outcomes_y)))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "pmk8qVvJ_xDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up training, hyperparameters etc. From Tutorial 9:\n",
        "\n",
        "The BERT authors have some recommendations for fine-tuning:\n",
        "\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5:, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ],
      "metadata": {
        "id": "NAzU9X5HACZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.001, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtH_ixzsAAfN",
        "outputId": "a60b4906-dc98-4bac-882c-1bb82703410e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for training the model for one epoch.\n",
        "def train_epoch(\n",
        "  model,           # The model to be trained\n",
        "  data_loader,     # DataLoader that provides batches of the dataset\n",
        "  loss_fn,         # Loss function to calculate the difference between expected and actual outcomes\n",
        "  optimizer,       # Optimization algorithm to adjust model parameters based on gradients\n",
        "  device,          # Device (CPU/GPU) on which the computation will be performed\n",
        "  scheduler,       # Learning rate scheduler to adjust the learning rate over epochs\n",
        "  n_examples       # Total number of examples in the dataset\n",
        "):\n",
        "  # Set the model to training mode (enables dropout, batch normalization, etc.)\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []  # List to store the loss of each batch\n",
        "  correct_predictions = 0  # Counter for the number of correct predictions\n",
        "\n",
        "  # Iterate over each batch in the data loader\n",
        "  for d in data_loader:\n",
        "    # Move the batch data to the specified device\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    # Forward pass: compute the model outputs with input_ids and attention_mask\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    # Compute the predictions by finding the index of the max logit\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    # Calculate the loss between the model outputs and true targets\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    # Count correct predictions to calculate accuracy\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    # Append the loss of the current batch to the list\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "\n",
        "    #debugging: view gradients\n",
        "    gradients = model.out.weight.grad\n",
        "    #print(gradients)\n",
        "\n",
        "    # Clip gradients to prevent the exploding gradient problem\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    # Perform a single optimization step (parameter update)\n",
        "    optimizer.step()\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "    # Clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  # Calculate the average accuracy and loss over all examples\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "t2CSu3NxAHXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for evaluating the model's performance on a dataset.\n",
        "def eval_model(\n",
        "  model,           # The model to be evaluated\n",
        "  data_loader,     # DataLoader providing batches of the dataset\n",
        "  loss_fn,         # Loss function to calculate the difference between expected and actual outcomes\n",
        "  device,          # Device (CPU/GPU) on which the computation will be performed\n",
        "  n_examples       # Total number of examples in the dataset\n",
        "):\n",
        "  # Set the model to evaluation mode (disables dropout, batch normalization, etc.)\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []  # List to store the loss of each batch\n",
        "  correct_predictions = 0  # Counter for the number of correct predictions\n",
        "\n",
        "  # Disable gradient computation to save memory and computation during evaluation\n",
        "  with torch.no_grad():\n",
        "    # Iterate over each batch in the data loader\n",
        "    for d in data_loader:\n",
        "      # Move the batch data to the specified device\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      # Forward pass: compute the model outputs with input_ids and attention_mask\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "\n",
        "      # Compute the predictions by finding the index of the max logit\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      # Calculate the loss between the model outputs and true targets\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      # Count correct predictions to calculate accuracy\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      # Append the loss of the current batch to the list\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  # Calculate the average accuracy and loss over all examples\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n"
      ],
      "metadata": {
        "id": "OfCaudCMAK_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state_10.bin') # save best model\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w3Mcw9HjAM2P",
        "outputId": "628ee6b5-4f50-4ef5-e768-634e15a5f7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.3566497249994427 accuracy 0.4594594594594595\n",
            "Val   loss 1.7034083895850927 accuracy 0.4845360824742268\n",
            "\n",
            "Epoch 2/20\n",
            "----------\n",
            "Train loss 1.1533558927476406 accuracy 0.4968814968814969\n",
            "Val   loss 0.7604777216911316 accuracy 0.4845360824742268\n",
            "\n",
            "Epoch 3/20\n",
            "----------\n",
            "Train loss 0.930377658456564 accuracy 0.47193347193347196\n",
            "Val   loss 0.7740173935890198 accuracy 0.5154639175257731\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d4d513051c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
            "    ready = selector.select(timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 7911) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "LXgtbnQ7-gAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNET0ubBBt4T",
        "outputId": "1724a895-4870-451a-9592-e05934692255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5041322314049587"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Emotional content of stories"
      ],
      "metadata": {
        "id": "kYmhzoOm0fLi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "315b7Bcl5Sde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Using a pre-trained emotion detection model available on huggingface3 , get a probability\n",
        "distribution for each sentence in each story. Average these probability vectors together to get\n",
        "an emotion vector for each story. For each story, the metadata provides a “theme\" field\n",
        "associated with each story: \"Rebellion\", \"Discovery\", \"Betrayal\", and \"Redemption\".\n",
        "Investigate whether and how the emotional content differs across the four “theme\" categories"
      ],
      "metadata": {
        "id": "c3ZCksba1BON"
      }
    }
  ]
}